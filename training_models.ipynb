{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install load_dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QFnic_OP3cG",
        "outputId": "eac820c2-0be4-4260-c8d6-756a396f9226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting load_dotenv\n",
            "  Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, load_dotenv\n",
            "Successfully installed load_dotenv-0.1.0 python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za1jdOMJPiXo",
        "outputId": "1fa1d503-86e3-4dd0-bacd-981ef84ce347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 850 images belonging to 17 classes.\n",
            "Found 821 images belonging to 17 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "<ipython-input-4-a65ce018e0c6>:128: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_batches,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7698 - accuracy: 0.0541\n",
            "Epoch 4: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 227s 8s/step - loss: 3.7698 - accuracy: 0.0541 - val_loss: 16.3220 - val_accuracy: 0.0609 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4831 - accuracy: 0.0612"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "TRAIN_DATASET_PATH = \"/content/drive/MyDrive/AWS/lamps/train\"\n",
        "VALIDATION_DATASET_PATH = \"/content/drive/MyDrive/AWS/lamps/validation\"\n",
        "BATCH_SIZE = 32\n",
        "N_CLASSES = 17\n",
        "TOTAL_EPOCHS = 10\n",
        "\n",
        "# Generators\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=TRAIN_DATASET_PATH,\n",
        "    target_size=[350, 350],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255\n",
        ")\n",
        "\n",
        "val_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=VALIDATION_DATASET_PATH,\n",
        "    target_size=[350, 350],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model\n",
        "kernel_initializer = tf.keras.initializers.glorot_uniform(seed=1337)\n",
        "trained_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "                      include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      alpha=0.5,\n",
        "                      input_shape=[350, 350, 3],\n",
        "                      pooling='max')\n",
        "output = tf.keras.layers.Dense(N_CLASSES, activation='softmax', kernel_initializer=kernel_initializer)(trained_model.output)\n",
        "model = tf.keras.Model(inputs=trained_model.input, outputs=output)\n",
        "\n",
        "# Callback to save weights, based on val_acc, old version in keras\n",
        "# Callback to save weights, based on val_accuracy\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  './checkpoints/{epoch:02d}_{val_accuracy:.4f}.h5',\n",
        "  save_weights_only=False,\n",
        "  verbose=1,\n",
        "  monitor='val_accuracy',\n",
        "  save_best_only=True,\n",
        "  mode='max'\n",
        ")\n",
        "\n",
        "\n",
        "# Callbackto plot data on TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "  log_dir='./logs/furniture_classifier',\n",
        "  histogram_freq=0,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Callback to reduce learning rate after plateaus\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "  monitor='val_acc',\n",
        "  factor=0.5,\n",
        "  patience=4,\n",
        "  min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_acc',\n",
        "  patience=20,\n",
        "  mode='max',\n",
        ")\n",
        "\n",
        "TRAIN_DATASET_SIZE = len(train_batches)\n",
        "VAL_DATASET_SIZE   = len(val_batches)\n",
        "\n",
        "# Weighted losses for class equilibrium\n",
        "unique, counts = np.unique(train_batches.classes, return_counts=True)\n",
        "class_weigths = dict(zip(unique, np.true_divide(counts.sum(), N_CLASSES*counts)))\n",
        "\n",
        "\n",
        "if Path('./checkpoints/').exists():\n",
        "  epoch_number_array = []\n",
        "  val_accuracy_array = []\n",
        "  file_name_array = []\n",
        "  for file in os.listdir('./checkpoints/'):\n",
        "    epoch, val_acc = re.search(r'(\\d\\d)_(\\d\\.\\d{4})\\.h5', file).group(1,2)\n",
        "    epoch_number_array.append(int(epoch))\n",
        "    val_accuracy_array.append(float(val_acc))\n",
        "    file_name_array.append(file)\n",
        "\n",
        "  if len(val_accuracy_array) == 0:\n",
        "    INITIAL_EPOCH = 0\n",
        "  else:\n",
        "    highest_acc = val_accuracy_array.index(max(val_accuracy_array))\n",
        "    INITIAL_EPOCH = epoch_number_array[highest_acc]\n",
        "    model_checkpoint_callback.best = val_accuracy_array[highest_acc]\n",
        "    model.load_weights('./checkpoints/'+file_name_array[highest_acc])\n",
        "else:\n",
        "  os.makedirs('./checkpoints/')\n",
        "  INITIAL_EPOCH = 0\n",
        "\n",
        "\n",
        "# Prepare model to run\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "\n",
        "# Starts training the model\n",
        "model.fit_generator(train_batches,\n",
        "                    epochs=TOTAL_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=TRAIN_DATASET_SIZE,\n",
        "                    validation_data=val_batches,\n",
        "                    validation_steps=VAL_DATASET_SIZE,\n",
        "                    initial_epoch=INITIAL_EPOCH,\n",
        "                    class_weight=class_weigths,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    callbacks=[model_checkpoint_callback, tensorboard_callback, reduce_lr_callback, early_stopping_callback]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"model_lamp.h5\", save_format='h5', include_optimizer=True, save_traces=True)\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(\"model_lamp.h5\")\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = \"/content/drive/MyDrive/AWS/lamps/train/Asian/13898asian-table-lamps.jpg\"\n",
        "img = tf.keras.preprocessing.image.load_img(image_path, target_size=[224, 224])\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create batch axis\n",
        "img_array = img_array / 255.0 # Normalize pixel values\n",
        "prediction = loaded_model.predict(img_array)\n",
        "class_index = np.argmax(prediction)\n",
        "class_names = list(train_batches.class_indices.keys())\n",
        "print(class_index)\n",
        "print(class_names)\n",
        "\n",
        "predicted_class = class_names[class_index]\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVBhedhn4dEv",
        "outputId": "0c5b4577-f383-4b6e-acd9-3f8260afa5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 649ms/step\n",
            "16\n",
            "['Asian', 'Beach', 'Contemporary', 'Craftsman', 'Eclectic', 'Farmhouse', 'Industrial', 'Mediterranean', 'Midcentury', 'Modern', 'Rustic', 'Scandinavian', 'Southwestern', 'Traditional', 'Transitional', 'Tropical', 'Victorian']\n",
            "Victorian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = list(train_batches.class_indices.keys())\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoaGZcMCBoIG",
        "outputId": "7187f1f0-2287-4c02-9739-58bf1af4d8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Asian', 'Beach', 'Contemporary', 'Craftsman', 'Eclectic', 'Farmhouse', 'Industrial', 'Mediterranean', 'Midcentury', 'Modern', 'Rustic', 'Scandinavian', 'Southwestern', 'Traditional', 'Transitional', 'Tropical', 'Victorian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "TRAIN_DATASET_PATH = \"/content/drive/MyDrive/AWS/beds/train\"\n",
        "VALIDATION_DATASET_PATH = \"/content/drive/MyDrive/AWS/beds/validation\"\n",
        "BATCH_SIZE = 32\n",
        "N_CLASSES = 17\n",
        "TOTAL_EPOCHS = 10\n",
        "\n",
        "# Generators\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=TRAIN_DATASET_PATH,\n",
        "    target_size=[224, 224],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255\n",
        ")\n",
        "\n",
        "val_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=VALIDATION_DATASET_PATH,\n",
        "    target_size=[224, 224],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model\n",
        "kernel_initializer = tf.keras.initializers.glorot_uniform(seed=1337)\n",
        "trained_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "                      include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      alpha=0.5,\n",
        "                      input_shape=[224, 224, 3],\n",
        "                      pooling='max')\n",
        "output = tf.keras.layers.Dense(N_CLASSES, activation='softmax', kernel_initializer=kernel_initializer)(trained_model.output)\n",
        "model = tf.keras.Model(inputs=trained_model.input, outputs=output)\n",
        "\n",
        "# Callback to save weights, based on val_acc, old version in keras\n",
        "# Callback to save weights, based on val_accuracy\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  './checkpoints/{epoch:02d}_{val_accuracy:.4f}.h5',\n",
        "  save_weights_only=False,\n",
        "  verbose=1,\n",
        "  monitor='val_accuracy',\n",
        "  save_best_only=True,\n",
        "  mode='max'\n",
        ")\n",
        "\n",
        "\n",
        "# Callbackto plot data on TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "  log_dir='./logs/furniture_classifier',\n",
        "  histogram_freq=0,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Callback to reduce learning rate after plateaus\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "  monitor='val_acc',\n",
        "  factor=0.5,\n",
        "  patience=4,\n",
        "  min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_acc',\n",
        "  patience=20,\n",
        "  mode='max',\n",
        ")\n",
        "\n",
        "TRAIN_DATASET_SIZE = len(train_batches)\n",
        "VAL_DATASET_SIZE   = len(val_batches)\n",
        "\n",
        "# Weighted losses for class equilibrium\n",
        "unique, counts = np.unique(train_batches.classes, return_counts=True)\n",
        "class_weigths = dict(zip(unique, np.true_divide(counts.sum(), N_CLASSES*counts)))\n",
        "\n",
        "\n",
        "if Path('./checkpoints/').exists():\n",
        "  epoch_number_array = []\n",
        "  val_accuracy_array = []\n",
        "  file_name_array = []\n",
        "  for file in os.listdir('./checkpoints/'):\n",
        "    epoch, val_acc = re.search(r'(\\d\\d)_(\\d\\.\\d{4})\\.h5', file).group(1,2)\n",
        "    epoch_number_array.append(int(epoch))\n",
        "    val_accuracy_array.append(float(val_acc))\n",
        "    file_name_array.append(file)\n",
        "\n",
        "  if len(val_accuracy_array) == 0:\n",
        "    INITIAL_EPOCH = 0\n",
        "  else:\n",
        "    highest_acc = val_accuracy_array.index(max(val_accuracy_array))\n",
        "    INITIAL_EPOCH = epoch_number_array[highest_acc]\n",
        "    model_checkpoint_callback.best = val_accuracy_array[highest_acc]\n",
        "    model.load_weights('./checkpoints/'+file_name_array[highest_acc])\n",
        "else:\n",
        "  os.makedirs('./checkpoints/')\n",
        "  INITIAL_EPOCH = 0\n",
        "\n",
        "\n",
        "# Prepare model to run\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "\n",
        "# Starts training the model\n",
        "model.fit_generator(train_batches,\n",
        "                    epochs=TOTAL_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=TRAIN_DATASET_SIZE,\n",
        "                    validation_data=val_batches,\n",
        "                    validation_steps=VAL_DATASET_SIZE,\n",
        "                    initial_epoch=INITIAL_EPOCH,\n",
        "                    class_weight=class_weigths,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    callbacks=[model_checkpoint_callback, tensorboard_callback, reduce_lr_callback, early_stopping_callback]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNXBqDZ2LE75",
        "outputId": "89f7d2f5-1209-4aec-dbff-af2db6a55ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 723 images belonging to 17 classes.\n",
            "Found 515 images belonging to 17 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "<ipython-input-1-8ff3f8db5089>:128: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_batches,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 3.4603 - accuracy: 0.0415\n",
            "Epoch 4: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 85s 3s/step - loss: 3.4603 - accuracy: 0.0415 - val_loss: 20.7989 - val_accuracy: 0.0291 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 7.0458 - accuracy: 0.0553\n",
            "Epoch 5: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 74s 3s/step - loss: 7.0458 - accuracy: 0.0553 - val_loss: 20.8759 - val_accuracy: 0.0136 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 3.5873 - accuracy: 0.0443\n",
            "Epoch 6: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 72s 3s/step - loss: 3.5873 - accuracy: 0.0443 - val_loss: 15.4380 - val_accuracy: 0.0136 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 3.5208 - accuracy: 0.0443\n",
            "Epoch 7: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 73s 3s/step - loss: 3.5208 - accuracy: 0.0443 - val_loss: 11.4960 - val_accuracy: 0.0971 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 3.2095 - accuracy: 0.0553\n",
            "Epoch 8: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 72s 3s/step - loss: 3.2095 - accuracy: 0.0553 - val_loss: 19.1008 - val_accuracy: 0.0311 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 3.2763 - accuracy: 0.0512\n",
            "Epoch 9: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 76s 3s/step - loss: 3.2763 - accuracy: 0.0512 - val_loss: 9.0876 - val_accuracy: 0.0311 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - ETA: 0s - loss: 2.9805 - accuracy: 0.0650\n",
            "Epoch 10: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/23 [==============================] - 73s 3s/step - loss: 2.9805 - accuracy: 0.0650 - val_loss: 8.2814 - val_accuracy: 0.0311 - lr: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d2e0692e0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"model_bed.h5\", save_format='h5', include_optimizer=True, save_traces=True)\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(\"model_bed.h5\")\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = \"/content/drive/MyDrive/AWS/lamps/train/Asian/13898asian-table-lamps.jpg\"\n",
        "img = tf.keras.preprocessing.image.load_img(image_path, target_size=[224, 224])\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create batch axis\n",
        "img_array = img_array / 255.0 # Normalize pixel values\n",
        "prediction = loaded_model.predict(img_array)\n",
        "class_index = np.argmax(prediction)\n",
        "class_names = list(train_batches.class_indices.keys())\n",
        "print(class_index)\n",
        "predicted_class = class_names[class_index]\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuNgwor7Qt_m",
        "outputId": "5c5944f9-ef11-49c8-bd13-58e6196e3959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 622ms/step\n",
            "0\n",
            "Asian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "TRAIN_DATASET_PATH = \"/content/drive/MyDrive/AWS/dressers/train\"\n",
        "VALIDATION_DATASET_PATH = \"/content/drive/MyDrive/AWS/dressers/validation\"\n",
        "BATCH_SIZE = 32\n",
        "N_CLASSES = 17\n",
        "TOTAL_EPOCHS = 10\n",
        "\n",
        "# Generators\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=TRAIN_DATASET_PATH,\n",
        "    target_size=[224, 224],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255\n",
        ")\n",
        "\n",
        "val_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=VALIDATION_DATASET_PATH,\n",
        "    target_size=[224, 224],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model\n",
        "kernel_initializer = tf.keras.initializers.glorot_uniform(seed=1337)\n",
        "trained_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "                      include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      alpha=0.5,\n",
        "                      input_shape=[224, 224, 3],\n",
        "                      pooling='max')\n",
        "output = tf.keras.layers.Dense(N_CLASSES, activation='softmax', kernel_initializer=kernel_initializer)(trained_model.output)\n",
        "model = tf.keras.Model(inputs=trained_model.input, outputs=output)\n",
        "\n",
        "# Callback to save weights, based on val_acc, old version in keras\n",
        "# Callback to save weights, based on val_accuracy\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  './checkpoints/{epoch:02d}_{val_accuracy:.4f}.h5',\n",
        "  save_weights_only=False,\n",
        "  verbose=1,\n",
        "  monitor='val_accuracy',\n",
        "  save_best_only=True,\n",
        "  mode='max'\n",
        ")\n",
        "\n",
        "\n",
        "# Callbackto plot data on TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "  log_dir='./logs/furniture_classifier',\n",
        "  histogram_freq=0,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Callback to reduce learning rate after plateaus\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "  monitor='val_acc',\n",
        "  factor=0.5,\n",
        "  patience=4,\n",
        "  min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_acc',\n",
        "  patience=20,\n",
        "  mode='max',\n",
        ")\n",
        "\n",
        "TRAIN_DATASET_SIZE = len(train_batches)\n",
        "VAL_DATASET_SIZE   = len(val_batches)\n",
        "\n",
        "# Weighted losses for class equilibrium\n",
        "unique, counts = np.unique(train_batches.classes, return_counts=True)\n",
        "class_weigths = dict(zip(unique, np.true_divide(counts.sum(), N_CLASSES*counts)))\n",
        "\n",
        "\n",
        "if Path('./checkpoints/').exists():\n",
        "  epoch_number_array = []\n",
        "  val_accuracy_array = []\n",
        "  file_name_array = []\n",
        "  for file in os.listdir('./checkpoints/'):\n",
        "    epoch, val_acc = re.search(r'(\\d\\d)_(\\d\\.\\d{4})\\.h5', file).group(1,2)\n",
        "    epoch_number_array.append(int(epoch))\n",
        "    val_accuracy_array.append(float(val_acc))\n",
        "    file_name_array.append(file)\n",
        "\n",
        "  if len(val_accuracy_array) == 0:\n",
        "    INITIAL_EPOCH = 0\n",
        "  else:\n",
        "    highest_acc = val_accuracy_array.index(max(val_accuracy_array))\n",
        "    INITIAL_EPOCH = epoch_number_array[highest_acc]\n",
        "    model_checkpoint_callback.best = val_accuracy_array[highest_acc]\n",
        "    model.load_weights('./checkpoints/'+file_name_array[highest_acc])\n",
        "else:\n",
        "  os.makedirs('./checkpoints/')\n",
        "  INITIAL_EPOCH = 0\n",
        "\n",
        "\n",
        "# Prepare model to run\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "\n",
        "# Starts training the model\n",
        "model.fit_generator(train_batches,\n",
        "                    epochs=TOTAL_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=TRAIN_DATASET_SIZE,\n",
        "                    validation_data=val_batches,\n",
        "                    validation_steps=VAL_DATASET_SIZE,\n",
        "                    initial_epoch=INITIAL_EPOCH,\n",
        "                    class_weight=class_weigths,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    callbacks=[model_checkpoint_callback, tensorboard_callback, reduce_lr_callback, early_stopping_callback]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpFPFhYsc8Iy",
        "outputId": "48372d2f-b759-4a3a-9924-d390f39ab575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 741 images belonging to 17 classes.\n",
            "Found 655 images belonging to 17 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "<ipython-input-1-d6cef41cc860>:128: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_batches,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 4.8999 - accuracy: 0.0688\n",
            "Epoch 4: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 85s 3s/step - loss: 4.8999 - accuracy: 0.0688 - val_loss: 20.3091 - val_accuracy: 0.0595 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 4.4646 - accuracy: 0.0729\n",
            "Epoch 5: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 75s 3s/step - loss: 4.4646 - accuracy: 0.0729 - val_loss: 16.4642 - val_accuracy: 0.0702 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 3.8390 - accuracy: 0.0486\n",
            "Epoch 6: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 78s 3s/step - loss: 3.8390 - accuracy: 0.0486 - val_loss: 13.6241 - val_accuracy: 0.0061 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 3.4718 - accuracy: 0.0364\n",
            "Epoch 7: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 78s 3s/step - loss: 3.4718 - accuracy: 0.0364 - val_loss: 13.8935 - val_accuracy: 0.0595 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 3.0624 - accuracy: 0.0486\n",
            "Epoch 8: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 74s 3s/step - loss: 3.0624 - accuracy: 0.0486 - val_loss: 14.6161 - val_accuracy: 0.0763 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 2.9787 - accuracy: 0.0499\n",
            "Epoch 9: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 74s 3s/step - loss: 2.9787 - accuracy: 0.0499 - val_loss: 14.4617 - val_accuracy: 0.0595 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 3.0397 - accuracy: 0.0432\n",
            "Epoch 10: val_accuracy did not improve from 0.09710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 75s 3s/step - loss: 3.0397 - accuracy: 0.0432 - val_loss: 11.1534 - val_accuracy: 0.0763 - lr: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f19831ddcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"model_dresser.h5\", save_format='h5', include_optimizer=True, save_traces=True)\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(\"model_bed.h5\")\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = \"/content/drive/MyDrive/AWS/lamps/train/Asian/13898asian-table-lamps.jpg\"\n",
        "img = tf.keras.preprocessing.image.load_img(image_path, target_size=[224, 224])\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create batch axis\n",
        "img_array = img_array / 255.0 # Normalize pixel values\n",
        "prediction = loaded_model.predict(img_array)\n",
        "class_index = np.argmax(prediction)\n",
        "class_names = list(train_batches.class_indices.keys())\n",
        "print(class_index)\n",
        "predicted_class = class_names[class_index]\n",
        "print(predicted_class)\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_ynRr1uiVf9",
        "outputId": "696209d2-be25-41a8-d275-cf6a89e8b92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 603ms/step\n",
            "0\n",
            "Asian\n",
            "['Asian', 'Beach', 'Contemporary', 'Craftsman', 'Eclectic', 'Farmhouse', 'Industrial', 'Mediterranean', 'Midcentury', 'Modern', 'Rustic', 'Scandinavian', 'Southwestern', 'Traditional', 'Transitional', 'Tropical', 'Victorian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "TRAIN_DATASET_PATH = \"/content/drive/MyDrive/AWS/chairs/train\"\n",
        "VALIDATION_DATASET_PATH = \"/content/drive/MyDrive/AWS/chairs/validation\"\n",
        "BATCH_SIZE = 32\n",
        "N_CLASSES = 17\n",
        "TOTAL_EPOCHS = 10\n",
        "\n",
        "# Generators\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=TRAIN_DATASET_PATH,\n",
        "    target_size=[224, 224],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    data_format='channels_last',\n",
        "    rescale=1. / 255\n",
        ")\n",
        "\n",
        "val_batches = train_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=VALIDATION_DATASET_PATH,\n",
        "    target_size=[224, 224],\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model\n",
        "kernel_initializer = tf.keras.initializers.glorot_uniform(seed=1337)\n",
        "trained_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "                      include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      alpha=0.5,\n",
        "                      input_shape=[224, 224, 3],\n",
        "                      pooling='max')\n",
        "output = tf.keras.layers.Dense(N_CLASSES, activation='softmax', kernel_initializer=kernel_initializer)(trained_model.output)\n",
        "model = tf.keras.Model(inputs=trained_model.input, outputs=output)\n",
        "\n",
        "# Callback to save weights, based on val_acc, old version in keras\n",
        "# Callback to save weights, based on val_accuracy\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "  './checkpoints/{epoch:02d}_{val_accuracy:.4f}.h5',\n",
        "  save_weights_only=False,\n",
        "  verbose=1,\n",
        "  monitor='val_accuracy',\n",
        "  save_best_only=True,\n",
        "  mode='max'\n",
        ")\n",
        "\n",
        "\n",
        "# Callbackto plot data on TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "  log_dir='./logs/furniture_classifier',\n",
        "  histogram_freq=0,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Callback to reduce learning rate after plateaus\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "  monitor='val_acc',\n",
        "  factor=0.5,\n",
        "  patience=4,\n",
        "  min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_acc',\n",
        "  patience=20,\n",
        "  mode='max',\n",
        ")\n",
        "\n",
        "TRAIN_DATASET_SIZE = len(train_batches)\n",
        "VAL_DATASET_SIZE   = len(val_batches)\n",
        "\n",
        "# Weighted losses for class equilibrium\n",
        "unique, counts = np.unique(train_batches.classes, return_counts=True)\n",
        "class_weigths = dict(zip(unique, np.true_divide(counts.sum(), N_CLASSES*counts)))\n",
        "\n",
        "\n",
        "if Path('./checkpoints/').exists():\n",
        "  epoch_number_array = []\n",
        "  val_accuracy_array = []\n",
        "  file_name_array = []\n",
        "  for file in os.listdir('./checkpoints/'):\n",
        "    epoch, val_acc = re.search(r'(\\d\\d)_(\\d\\.\\d{4})\\.h5', file).group(1,2)\n",
        "    epoch_number_array.append(int(epoch))\n",
        "    val_accuracy_array.append(float(val_acc))\n",
        "    file_name_array.append(file)\n",
        "\n",
        "  if len(val_accuracy_array) == 0:\n",
        "    INITIAL_EPOCH = 0\n",
        "  else:\n",
        "    highest_acc = val_accuracy_array.index(max(val_accuracy_array))\n",
        "    INITIAL_EPOCH = epoch_number_array[highest_acc]\n",
        "    model_checkpoint_callback.best = val_accuracy_array[highest_acc]\n",
        "    model.load_weights('./checkpoints/'+file_name_array[highest_acc])\n",
        "else:\n",
        "  os.makedirs('./checkpoints/')\n",
        "  INITIAL_EPOCH = 0\n",
        "\n",
        "\n",
        "# Prepare model to run\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "\n",
        "# Starts training the model\n",
        "model.fit_generator(train_batches,\n",
        "                    epochs=TOTAL_EPOCHS,\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=TRAIN_DATASET_SIZE,\n",
        "                    validation_data=val_batches,\n",
        "                    validation_steps=VAL_DATASET_SIZE,\n",
        "                    initial_epoch=INITIAL_EPOCH,\n",
        "                    class_weight=class_weigths,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=4,\n",
        "                    callbacks=[model_checkpoint_callback, tensorboard_callback, reduce_lr_callback, early_stopping_callback]\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qwDvKqwzO8v",
        "outputId": "a590730d-3f12-4dbe-8bf7-5a7127217cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 850 images belonging to 17 classes.\n",
            "Found 829 images belonging to 17 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.5_224_no_top.h5\n",
            "3201480/3201480 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "<ipython-input-4-50e098897b78>:128: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_batches,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 8.2127 - accuracy: 0.0635\n",
            "Epoch 1: val_accuracy improved from -inf to 0.06031, saving model to ./checkpoints/01_0.0603.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 203s 7s/step - loss: 8.2127 - accuracy: 0.0635 - val_loss: 17.7096 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.6110 - accuracy: 0.0529\n",
            "Epoch 2: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 135s 5s/step - loss: 4.6110 - accuracy: 0.0529 - val_loss: 19.8182 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9845 - accuracy: 0.0600\n",
            "Epoch 3: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 140s 5s/step - loss: 3.9845 - accuracy: 0.0600 - val_loss: 24.3170 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1780 - accuracy: 0.0494\n",
            "Epoch 4: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 139s 5s/step - loss: 4.1780 - accuracy: 0.0494 - val_loss: 120.5102 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.2842 - accuracy: 0.0588\n",
            "Epoch 5: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 145s 5s/step - loss: 4.2842 - accuracy: 0.0588 - val_loss: 41.0130 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.3997 - accuracy: 0.0671\n",
            "Epoch 6: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 148s 5s/step - loss: 4.3997 - accuracy: 0.0671 - val_loss: 55.3545 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 7.3674 - accuracy: 0.0671\n",
            "Epoch 7: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 139s 5s/step - loss: 7.3674 - accuracy: 0.0671 - val_loss: 23.3176 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1260 - accuracy: 0.0682\n",
            "Epoch 8: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 153s 5s/step - loss: 4.1260 - accuracy: 0.0682 - val_loss: 13.8145 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7523 - accuracy: 0.0800\n",
            "Epoch 9: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 145s 5s/step - loss: 3.7523 - accuracy: 0.0800 - val_loss: 11.7679 - val_accuracy: 0.0603 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4823 - accuracy: 0.0529\n",
            "Epoch 10: val_accuracy did not improve from 0.06031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 147s 5s/step - loss: 3.4823 - accuracy: 0.0529 - val_loss: 18.2067 - val_accuracy: 0.0350 - lr: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa8172721c0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"model_chair.h5\", save_format='h5', include_optimizer=True, save_traces=True)\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(\"model_chair.h5\")\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = \"/content/drive/MyDrive/AWS/lamps/train/Asian/13898asian-table-lamps.jpg\"\n",
        "img = tf.keras.preprocessing.image.load_img(image_path, target_size=[224, 224])\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create batch axis\n",
        "img_array = img_array / 255.0 # Normalize pixel values\n",
        "prediction = loaded_model.predict(img_array)\n",
        "class_index = np.argmax(prediction)\n",
        "class_names = list(train_batches.class_indices.keys())\n",
        "print(class_index)\n",
        "predicted_class = class_names[class_index]\n",
        "print(predicted_class)\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BlkQbzNzxl0",
        "outputId": "2190af91-1f25-4357-c7ec-4e5f9e6af04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "12\n",
            "Southwestern\n",
            "['Asian', 'Beach', 'Contemporary', 'Craftsman', 'Eclectic', 'Farmhouse', 'Industrial', 'Mediterranean', 'Midcentury', 'Modern', 'Rustic', 'Scandinavian', 'Southwestern', 'Traditional', 'Transitional', 'Tropical', 'Victorian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCA9fuUc1fzA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}